---
title: "Conductor script"
author: "N. Schenk"
date: "2022-11-16"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

# Aim
The analysis consists of various small (drone) scripts. The order is indicated, but instead of calling them by hand, giving the model names as inputs, this script does this job for you, as the hive does the coordination job for the drones. ([source](https://www.theserverside.com/opinion/Master-slave-terminology-alternatives-you-can-use-right-now) for hive-drone terminology).

The conductor script here calls the drone scripts of the analysis in order to run the full analysis from one place.

# Requirements

The script `vignettes/analysis_nonpublic.R` loads the necessary requirements, specifying the specific requirements by variable `sections_to_be_loaded`. Each section includes an option to load the requirements.

Requires access to the Plant Ecology Group (Fischer) drive "planteco" at the IPS Bern. See header of the `analysis_nonpublic.R` file.


# Sequence of analysis


## Prepare data
```{r}
#TODO add early scripts
```


## Fit models
Scripts depending on output of each other, need to run per model.

Requirements
```{r}
if(!exists("model_names")){
  sections_to_be_loaded <- c()
  source("vignettes/analysis_nonpublic.R")
}
```

### single model
Chose model by hand
```{r}
# select a given model
model_names_selection <- model_names[which(model_names$modelname == "gdm_EFturnover_0.7_LUI"), ]
#
# run analysis and create results
ksource("vignettes/prepare_and_run_GDM.Rmd") # default model : EF turnover 0.7 LUI
ksource("vignettes/check_GDM_input.Rmd") # produce nice plots/ results about correlations among input variables
ksource("vignettes/plot_modelwise_GDM.Rmd") # produce bar and line plots of the current model
```

### all models
Loop through all models. Dont forget to transfer the output from vignettes/out to `pathtodata`.
```{r, eval = F}
source("vignettes/analysis_nonpublic.R")

# run all single function and multifunctionality models
for(mod in model_names[model_class %in% c("multifun", "singlefun") & lui == "LUI", modelname]){
  model_names_selection <- model_names[which(model_names$modelname == mod), ]
  # run analysis and create results
  ksource("vignettes/prepare_and_run_GDM.Rmd") 
  ksource("vignettes/check_GDM_input.Rmd") # produce nice plots/ results about correlations among input variables
  ksource("vignettes/plot_modelwise_GDM.Rmd") # produce bar and line plots of the current model
}
```




## Permutations
Run on cluster
```{r}
# run cluster_scripts by hand on cluster!
print("run cluster_scripts_documentation.Rmd by hand on cluster!")
```




## Model output

Note : the below scripts only need to be run once, after the above scripts have been run for all models. 
```{r}
ksource("vignettes/check_GDM_diagnostics.Rmd") # 1 script for all model diagnostics
ksource("vignettes/plot_unique_GDM.Rmd") # plot single EF models 
ksource("vignettes/summarise_GDM_results.Rmd") # create summary tables of all model results (deviance explained and isplines)
```


## Threshold overview

### calculate sd

In order to calculate a summary model over all thresholds over all x values (not just maximum x, but a full line), the sd needs to be calculated everywhere.

Run the thresholds part of `cluster_scripts_documentation.Rmd` on the cluster.
If no cluster is available : create a script "**gdm_uncertainty.R**". Copy paste the part from `cluster_scripts_documentation.Rmd` in this file. Run it through all nestedness and turnover tresholds with LUI. Note that this script calculates sd for 1 model. In order to run through all, the input has been changed manually (you find code to change automatically in `cluster_scripts_documentation.Rmd`).
```{r, eval = F}
source("gdm_uncertainty.R")
```

The output are 18 .Rds files for thresholds 0.1 - 0.9 for turnover and nestedness. E.g. "analysis/output_datasets/uncertainty_calc/gdm_EFnestedness_0.8_LUI_uncertainty.Rds"



```{r}
#TODO probably add script : GDM_multifun_thresholds.Rmd
```

