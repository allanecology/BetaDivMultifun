---
title: "mini-multifunctionalities from imputed functions"
author: "Noelle Schenk"
date: "June 5, 2019"
output: html_document
---
This script :
- calculates the multifunctionalities from the imputed functions dataset
- select functions for the analysis
- combine years
- calculate functional dissimilarity


# Calculate mini-multifunctionalities
The mini-multifunctionalities are calculated from the imputed values.

## soilCflxs
Enzymes related to soil C. All measured in the year 2011.
```{r}
sce <- imputed_grlfuns[, c("beta_Glucosidase", "N_Acetyl_beta_Glucosaminidase", "Xylosidase")]
# take z-scores of the functions
imputed_grlfuns[, "soilCflxs" := multidiv(sce, sc="sd", cent=TRUE)[,1]]
imputed_grlfuns[, c("beta_Glucosidase", "N_Acetyl_beta_Glucosaminidase", "Xylosidase") := NULL]
rm(sce)
```

## soilNflxs
Enzymes related to soil N. A measure of soil N cycling with enzyme activities and functional gene abundances

amoA_AOB and A are from both 2011 and 2016, took the mean of both years.
```{r}
nce <- imputed_grlfuns[,c("Plotn", "Urease", "DEA","Potential.nitrification2011", "Potential.nitrification2014","nifH","amoA_AOB.2011","amoA_AOA.2011", "amoA_AOB.2016", "amoA_AOA.2016", "nxrA_NS", "16S_NB")]
# take mean of multi-year-measurements
nce[, "amoA_AOB" := apply(nce[,c("amoA_AOB.2011", "amoA_AOB.2016")],1, mean)]
nce[, "amoA_AOA" := apply(nce[,c("amoA_AOA.2011", "amoA_AOA.2016")],1, mean)]
nce[, "Potential.nitrification" := apply(nce[, c("Potential.nitrification2014", "Potential.nitrification2011")], 1, mean)]
nce[, c("amoA_AOB.2011", "amoA_AOB.2016", "amoA_AOA.2011", "amoA_AOA.2016", "Potential.nitrification2014", "Potential.nitrification2011") := NULL]
```
There are two steps of soilNflxs
```{r, eval=T}
M <- Hmisc::rcorr(as.matrix(nce[, !"Plotn", with=F]), type = "spearman")
mr <- M$r
mp <- M$P
mp[mp > 0.05] <- 0 # remove nonsignificant at 5% level
# library("PerformanceAnalytics")
# chart.Correlation(nce[, !"Plotn", with=F], histogram=T, pch=19)
corrplot::corrplot(mr,type="lower",addCoef.col = "black",method="color",diag=F, tl.srt=1, tl.col="black", mar=c(0,0,0,0), number.cex=0.6, order = "hclust")
```
based on clustering and biology:
- ammonium is oxidised by bacteria and archaea (AOB, AOA)
- nitrate oxidation by bacteria (NS and NB)

these two steps are separated steps. The correlation of AO and NO is based on co-occurrence.

- ammonium oxidising group : AOA, AOB, urease (because this enzyme hydrolyses urea to ammonia and CO2)
- nitrate oxidising group : NS, NB, nifH, potential nitrification, DEA
```{r}
nce_a <- nce[, .(Plotn, amoA_AOB, amoA_AOA, Urease)]
nce_n <- nce[, .(Plotn, nxrA_NS, `16S_NB`, nifH, Potential.nitrification, DEA)]
```
calculating mini-multifunctionality of both groups
```{r}
imputed_grlfuns[, "soilAmmoniaflxs" := multidiv(nce_a[, !"Plotn", with=F], sc="sd", cent=T)[,1]]
imputed_grlfuns[, "soilNitrateflxs" := multidiv(nce_n[, !"Plotn", with=F], sc="sd", cent=T)[,1]]

rm(nce_n); rm(nce_a); rm(nce); rm(M); rm(mr); rm(mp)
imputed_grlfuns[,c("Urease", "DEA","Potential.nitrification2011", "Potential.nitrification2014","nifH","amoA_AOB.2011","amoA_AOA.2011", "amoA_AOB.2016", "amoA_AOA.2016", "nxrA_NS", "16S_NB") := NULL]
```

# P_loss_comb
```{r}
# plc <- imputed_grlfuns[, c("P_loss2011", "P_leaching_risk2015", "PRI", "PRI.2011")]
#TODO : HERE : need to impute PRI.2011 to use it for P_loss_comb!
plc <- imputed_grlfuns[, c("P_loss2011", "P_leaching_risk2015", "PRI")]
# take mean of P_loss 2011 and leaching risk 2015
plc[, "P_loss" := apply(plc[,c("P_loss2011", "P_leaching_risk2015")],1, mean)]
plc[, c("P_loss2011", "P_leaching_risk2015") := NULL]
# take mean of PRI
# ...

imputed_grlfuns[, "P_loss_comb" := multidiv(plc, sc="sd", cent=TRUE)[,1]]

rm(plc)
imputed_grlfuns[, c("P_loss2011", "P_leaching_risk2015", "PRI") := NULL]
# imputed_grlfuns[, c("P_loss2011", "P_leaching_risk2015", "PRI", "PRI.2011") := NULL]
```


# Select functions
selecting the functions which are used in analysis.
```{r}
# select variables which are included in betadiv multifun analysis
usedforBetadivMultifun <- usedforBetadivMultifun[!usedforBetadivMultifun == "Plot"]
#TODO : will take out once the soilNflxs "daughters" are official
usedforBetadivMultifun <- c(usedforBetadivMultifun[- which(usedforBetadivMultifun == "soilNflxs")], "soilAmmoniaflxs", "soilNitrateflxs")

imputed_grlfuns <- imputed_grlfuns[, ..usedforBetadivMultifun]
#TODO : save functions?
# saveRDS(imputed_grlfuns, "imputed_grlfuns.rds")
```

# Check Correlations
Of the non-factor columns only
```{r}
# the dataset is complete now, use "complete.obs" for the cor() function now
M <- cor(imputed_grlfuns[, !colnames(imputed_grlfuns) %in% "Plotn", with=F], use="complete.obs")

# imputed_grlfun_corrplot1
corrplot::corrplot(M,type="lower",addCoef.col = "black",method="color",diag=F, tl.srt=1, tl.col="black", mar=c(0,0,0,0), number.cex=0.6)

# imputed_grlfun_corrplot2
corrplot::corrplot(M, type = "upper", tl.col="black", tl.srt=40, diag = F)

# only show high correlations
tres <- 0.7
M[which(M < tres & M > -tres)] <- 0
corrplot::corrplot(M, type = "upper", tl.col="black", tl.srt=40, diag = F, main = "B")
```


# Dissimilarity of function

2 ways of dissimilarity calculation : 
- *EFturnover* and *EFnestedness* : calculate presence-absence of functions by 0.5 treshold, and then calculate betadiversity turnover and nestedness components of them.
- *EFdistance* : calculate PCA, identify most important axis, take euclidean distance of them to get a single value for each plot. 
    - open question : weighting of the PCA axis. Weighting by var explained gives the correlated functions too much weight. Equal weighting? Is chosen until better option is available.


## EFdistance calculation

From PCA of all functions, take most important axes and calculate euclidian distance of them (using equal weights). Note : not weighed by amount of variance explained or similar, because soil axis should not get too much weight. 

We expect that one of the important axis - possibly the first to represent soil. As we have many soil functions compared to aboveground functions, soil would otherwise get too much importance.
```{r}
# STANDARDISATION
include <- names(imputed_grlfuns)[!names(imputed_grlfuns) %in% "Plotn"]
imputed_grlfuns[, (include) := lapply(.SD, scale01),.SDcols=include]

# PCA
pc_grlfuns <- imputed_grlfuns[, ..include]
pc_grlfuns <- as.data.frame(pc_grlfuns)
rownames(pc_grlfuns) <- imputed_grlfuns$Plotn

pca_grlfuns <- stats::prcomp(pc_grlfuns, scale=F) 

plot(pca_grlfuns)
biplot(pca_grlfuns)
plot(ecdf(pca_grlfuns$sdev))
```
**axis selection** : 
first 5 axis explain 70 % of variance

There are groups of three axis which have about the same amount of variance explained. 
```{r}
pca_grlfuns <- pca_grlfuns$x[, 1:5]
# euclidean distance
EFdistance <- vegan::vegdist(pca_grlfuns, method = "euclid")

saveRDS(EFdistance, "EFdistance.rds")

rm(pca_grlfuns); rm(pc_grlfuns)
```


## EFturnover and EFnestedness
Based on a 50% treshold, classify for each function and each plot presence or absence of the given function. Based on the scaled functions.
TODO : do I really need to scale?

Demo with plot:
```{r}
# old code below

# percentage of measured functions that exceed a given treshold of their maximum observed level across all study sites.
# maximum observed level: average of the top five sites.
treshold <- 0.5
# tresholds used in Solivieres paper :  0.25,0.5,0.75,0.9
# to illustrate (outcomment if plot not wanted)
# barplot(x, las = 2)
x <- fungrl_pa[,get(colnames(fungrl_pa)[8])]
names(x) <- seq(1,130)
barplot(x, main=colnames(fungrl_pa)[8], xlab="Plots")
upper <- mean(sort(fungrl_pa[,get(colnames(fungrl_pa)[8])],decreasing = T, na.last=T)[1:5])
abline(a=upper,b=0,col="darkgreen") ; abline(a=upper*treshold, b=0, col="red")
# calc_presenceabsence(x)
fungrl_pa[, (mysubset) := lapply(.SD, function(c) calc_presenceabsence(c, treshold=treshold)),.SDcols=mysubset]
fungrl_pa[,(mysubset):= (.SD * 1), .SDcols=mysubset]
```


```{r}





# old code below


# option 2 : for loop, exclude column plot and don't change in-place
#  the for loop outputs beta diversities as a list of 3 for each given treshold value.
tresholds <- c(0.25,0.5,0.75,0.9)
for(i in tresholds){
  name <- paste("multifun_pa",i,sep='_')
  res <- apply(fungrl_pa[,!("Plot0")],2,function(c) calc_presenceabsence(c,treshold=i))
  res <- res * 1 ; rownames(res) <- fungrl[["Plot0"]]
  res <- beta.pair(res, index.family="sorensen")
  res <- lapply(res,as.matrix)
  res <- lapply(res, function(x) cbind("Plot" = seq(1,130,by=1),x))
  assign(name,res)
   # multifun berechnen mit untenstehendem code und dem namen zuweisen.
}
rm(name) ; rm(res) ; rm(i)
# for the moment, only include beta.sor (both values together)
multifun_pa_0.25 <- multifun_pa_0.25$beta.sor
multifun_pa_0.5 <- multifun_pa_0.5$beta.sor
multifun_pa_0.75 <- multifun_pa_0.75$beta.sor
multifun_pa_0.9 <- multifun_pa_0.9$beta.sor
```



TODO HERE : how to do that?

```{r}
require(reshape2)   # Note : require works as library, only if it doesn't work, it outputs a warning and not an error.
require(data.table) #        that's better in functions. (library throws an error)
require(betapart)
require(vegan)




# run the pca
pca_fungrl <- prcomp(pc_fungrl, scale=T)
plot(pca_fungrl)
biplot(pca_fungrl)
pc_fungrl <- scores(pca_fungrl, display="sites")
rownames(pc_fungrl) <- fungrl$Plotn

# compute DISSIMILARITY MATRICES
# compute dissimilarities for all principal components I got (10) (euclidian distance)
edis_fungrl <- vegdist(pc_fungrl, method= "euclid")

# the rows and columns are perfectly ordered, so I can use numbers from 1 to 130 as plot IDs.
# rownames(edis_fungrl) != sort(rownames(edis_fungrl))
edis_fungrl <- as.matrix(edis_fungrl)
edis_fungrl <- cbind("Plot" = seq(1,127,by=1),edis_fungrl) # NEW taken out and replaced by next column
# edis_fungrl <- cbind("Plot" = rownames(edis_fungrl), edis_fungrl)

#########################################
# 4. CALC P-A and sorensen DISSIMILARITY
#########################################
# percentage of measured functions that exceed a given treshold of their maximum observed level across all study sites.
# maximum observed level: average of the top five sites.
fungrl_pa <- as.data.table(fungrl)

# # # Option 1: only one treshold, but plot
# treshold <- 0.5
# # tresholds used in Solivieres paper :  0.25,0.5,0.75,0.9
# # to illustrate (outcomment if plot not wanted)
# # barplot(x, las = 2)
# x <- fungrl_pa[,get(colnames(fungrl_pa)[8])]
# names(x) <- seq(1,127)
# barplot(x, main=colnames(fungrl_pa)[8], xlab="Plots")
# upper <- mean(sort(fungrl_pa[,get(colnames(fungrl_pa)[8])],decreasing = T, na.last=T)[1:5])
# abline(a=upper,b=0,col="darkgreen") ; abline(a=upper*treshold, b=0, col="red")
# # calc_presenceabsence(x)
# calc_presenceabsence <- function(x,treshold){
#   # x is a vector
#   max_obs <- mean(sort(x,decreasing = T, na.last=T)[1:5])
#   new_vector <- x>(max_obs*treshold)
#   return(new_vector)
# }
# 
# fungrl_pa[, (mysubset) := lapply(.SD, function(c) calc_presenceabsence(c, treshold=treshold)),.SDcols=mysubset]
# fungrl_pa[,(mysubset):= (.SD * 1), .SDcols=mysubset]
# rownames(fungrl_pa) <- fungrl$Plotn

# option 2 : for loop, exclude column plot and don't change in-place
#  the for loop outputs beta diversities as a list of 3 for each given treshold value.
# tresholds <- c(0.25,0.5,0.75,0.9) # NEW make trehsholds vector of only one treshold
tresholds <- c(0.5)
for(i in tresholds){
  name <- paste("multifun_pa",i,sep='_')
  res <- apply(fungrl_pa[,!("Plotn")],2,function(c) calc_presenceabsence(c,treshold=i))
  res <- res * 1 ; rownames(res) <- fungrl$Plotn
  res <- beta.pair(res, index.family="sorensen")
  res <- lapply(res,as.matrix)
  res <- lapply(res, function(x) cbind("Plot" = seq(1,127,by=1),x))
  assign(name,res)
   # multifun berechnen mit untenstehendem code und dem namen zuweisen.
}
rm(name) ; rm(res) ; rm(i)
# for the moment, only include beta.sor (both values together)
# multifun_pa_0.25 <- multifun_pa_0.25$beta.sor
multifun_pa_0.5 <- multifun_pa_0.5$beta.sor
# multifun_pa_0.75 <- multifun_pa_0.75$beta.sor
# multifun_pa_0.9 <- multifun_pa_0.9$beta.sor

#########################################
# 5. CLEAN OUT
#########################################
rm(fungrl) ; rm(fungrl_pa) ; rm(pc_fungrl) ; rm(mysubset) ;  rm(pca_fungrl) ; rm(plot_NAset) ; rm(tresholds)
rm(names_fun) ; rm(impdat)
# if the large dataset is used

# if the small dataset is used
# rm(plot_NAset_small) ; rm(navals) ; rm(exclude)

```
