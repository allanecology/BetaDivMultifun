---
title: "Functions Processing for BetaDivMultifun"
output:
  pdf_document: default
  html_notebook: default
---
------------------------------------------------------------- 
TODO : where is this done? 

check distributions
normality?

log transform non-normally distributed ones

check distributions again
-------------------------------------------------------------

This Vignette relies on the BExIS grassland functions dataset.
TODO : add information on where to get it/ ask for access

It also relies on a soil information dataset, which is prepared by `prepare_covariates.Rmd`.

# Data
The dataset used for gap filling is larger than the dataset used for the analysis. More variables enhance the performance of gapfilling.
```{r}
#USER : insert path to grassland function file and read in as grlfuns (uncomment line below)
# grlfuns <- data.table::fread("<pathto_grl_functions.csv>", header=T)
```
Grassland functions data used for gapfilling is stored in `raw_grlfuns`, selected variables according to info data.








# Gap filling
A Gap-filling of the functions dataset is performed, because many values are missing (NA). To enhance the predictions of the gapfilling, soil data is included. This introduces a bias, but reduces the imputation error. 

TODO : It can be commented out. (search for "uncomment if not wanted")

TODO : Two variables are produced, impdat which contains the gapfilled dataset which will be used in further analysis as well as imp_err, which contains the imputation error automatically estimated by missForest.


## Data preparation
Soil predictor data and Region is included to improve Gap filling. uncomment if not wanted!
```{r}
#USER : uncomment this block if soil information should not be included.
remove <- unique(glsoil_unscaled$Soil.type)
glsoil_unscaled[, (remove) := NULL]
glsoil_unscaled[, Soil.type := as.factor(Soil.type)] # soil type as factor
rm(remove)
```

```{r}
befun <- merge(raw_grlfuns, glsoil_unscaled, by="Plotn")
befun[, Explo := as.factor(Explo)] # Region as a factor
#TODO : need to have parasitoid trap and all other columns which are "int" now as numeric?
```
cleaning out variables with too many missing values
```{r}
visdat::vis_miss(befun, sort_miss = T)
```
*VARIANT 1* : 
Values with over 21% missing data are excluded: mAMF hyphae, Parasitoid traps, Aggregation and pathogen infection.
```{r, eval=F}
#USER : set treshold for missing values
treshold <- 0.21
t <- apply(befun, 2, function(x) sum(is.na(x)))
exclude <- names(which(t > 150 * treshold))
befun <- befun[, !colnames(befun) %in% exclude, with=F]
rm(t); rm(exclude); rm(treshold)
```
*VARIANT 2* : only exclude pathogen infection, because all AEG are missing.
```{r}
befun[, pathogen.infection := NULL]
```


## Check Correlations
Of the non-factor columns only
```{r}
corrbefun <- befun[, !colnames(befun) %in% c("Explo", "Soil.type", "Plotn", "Plot"), with=F]
M <- cor(corrbefun, use="pairwise.complete.obs")

# raw_grlfun_corrplot1
corrplot::corrplot(M,type="lower",addCoef.col = "black",method="color",diag=F, tl.srt=1, tl.col="black", mar=c(0,0,0,0), number.cex=0.6)

# raw_grlfun_corrplot2
corrplot::corrplot(M, type = "upper", tl.col="black", tl.srt=40, diag = F)

# only show high correlations
tres <- 0.7
M[which(M < tres & M > -tres)] <- 0
corrplot::corrplot(M, type = "upper", tl.col="black", tl.srt=40, diag = F)
```
Network
```{r}
# show network - is there a variable "alone"? bzw. isolated?
network <- igraph::graph_from_adjacency_matrix(M, weighted=T, mode="undirected", diag=F)
plot(network)
```
There is no variable which is not connected with at least one line to another variable. Lines represent correlations > threshold.
```{r}
rm(M); rm(network)
```


## Log transformation
before changing values, store the original dataset
```{r}
befunbackup <- data.table::copy(befun)
```
remove negative values, remember to add again after imputation!

find negative values
```{r}
par(mar = c(10, 1, 3, 1))
boxplot(corrbefun, las=2)
# minimum of the numeric columns
negative <- colnames(corrbefun)[which(corrbefun[, lapply(.SD, function(x) min(x, na.rm=T))] < 0)]
```
remove negative values - shift whole vector up.
```{r}
# DEA
mindea <- min(befun$DEA, na.rm=T)
befun$DEA <- befun$DEA + abs(mindea)
# NO3.2014
minno <- min(befun$NO3.2014, na.rm=T)
befun$NO3.2014 <- befun$NO3.2014 + abs(minno)
# dung.decomposition
mindung <- min(befun$dung.decomposition, na.rm=T)
befun$dung.decomposition <- befun$dung.decomposition + abs(mindung)
rm(negative)
```
Log transformation of the numeric columns. The natural logartithm of values smaller than 1 is negative. Tehrefore, all values are shifted by 1 again to avoid any negative values in the log transformed dataset.
```{r}
numcols <- colnames(befun)[!colnames(befun) %in% c("Explo", "Soil.type", "Plotn", "Plot")]
befun[, (numcols) := lapply(.SD, as.numeric), .SDcols = numcols]
# log transform the values + 1, later shift them back.
befun[, (numcols) := lapply(.SD, function(x) log(x+1)), .SDcols = numcols]
# record NA value positions for visualistation
naloc <- is.na(befun)
```

## Imputation

### Imputation test
Find and evaluate the imputation error of a single iteration and optimise the process for 50x imputation. (The code for the imputation loop is copied, just one imputation done.)
```{r}
# based on one-time imputation, take out : "amoA_AOA.2016" ,"amoA_AOB.2016",  "nxrA_NS", "16S_NB"
#TODO : change back to plot and plotn only.
numcols <- numcols[which(!numcols %in% c("Plotn", "Plot", "amoA_AOA.2016" ,"amoA_AOB.2016",  "nxrA_NS", "16S_NB"))]
dataset <- befun[, !colnames(befun) %in% c("Plotn", "Plot", "amoA_AOA.2016" ,"amoA_AOB.2016",  "nxrA_NS", "16S_NB"), with=F]

# run one imputation with missforest.
returnobj <- perform_missforest_imputations(dataset = dataset, numcols = numcols, im=1)
imperr <- returnobj$errors
impvals <- returnobj$values
rm(returnobj)
```
Visualise imputation results.
```{r}
barplot(imperr[[1]][, columns], height=imperr[[1]][,errors])
library(cowplot)
p<-ggplot2::ggplot(data=imperr[[1]], ggplot2::aes(x=columns, y=errors)) +
  ggplot2::geom_bar(stat="identity") +
  theme(axis.text.x=element_text(color = "black", size=5, angle=30, vjust=.8, hjust=0.8)) +
  geom_hline(yintercept=0.25, linetype="dashed", color = "gray")
p
```
Need to take out Parasitoid traps, Potential nitrification (2011 and 2014) and total pollinators.
TODO : check if the imputation is better if only the selected plots are worked with.


```{r}
# USER : may change filename
saveRDS(impvals, file="raw_imputed_function_values_complete.rds")
# impvals <- readRDS("raw_imputed_function_values_complete.rds")
```


#---------------------------------------------------------------------------------------------------------------------------
from here : not done yet, want to check if it makes a difference if I already only use the plot set

The imputation is repeated 50 times, and the mean of the imputed values is taken. 
```{r imputation, results="hide", eval=F}
# 50 imputations
impvals <- list()
imperr <- list()
# based on one-time imputation, take out : "amoA_AOA.2016" ,"amoA_AOB.2016",  "nxrA_NS", "16S_NB"
#TODO : change back to plot and plotn only.
numcols <- numcols[which(!numcols %in% c("Plotn", "Plot", "amoA_AOA.2016" ,"amoA_AOB.2016",  "nxrA_NS", "16S_NB"))]
dataset <- befun[, !colnames(befun) %in% c("Plotn", "Plot", "amoA_AOA.2016" ,"amoA_AOB.2016",  "nxrA_NS", "16S_NB"), with=F]

for(i in 1:1){
  print(i)
  current <- missForest::missForest(dataset, variablewise = T)
  imperr[[i]] <- data.table::data.table("columns" = colnames(dataset), "errors" =current$OOBerror)
  current <- as.data.table(current$ximp)
  # re-transform the numeric variables
  current[, (numcols) := lapply(.SD, function(x) (exp(x)-1)), .SDcols = numcols]
  # re-transform the negative values
  current$DEA <- current$DEA - abs(mindea)
  current$NO3.2014 <- current$NO3.2014 - abs(minno)
  current$dung.decomposition <- current$dung.decomposition - abs(mindung)
  # add back the "Plotn" column which was taken out for imputation
  current[, Plotn := befun$Plotn]
  # convert imputed data.table to matrix, as more handy for imputed values handling
  impvals[[i]] <- current
}
rm(current); rm(i); rm(mindea); rm(minno); rm(mindung)
# USER : may change filename
saveRDS(impvals, file="raw_imputed_function_values_complete.rds")
# impvals <- readRDS("raw_imputed_function_values_complete.rds")
```

Check imputation error
```{r}
imperr <- do.call(rbind, imperr)
mean(imperr[,1])
#TODO : need to to once the imperr is there
plot(rep(1, nrow(imperr)), imperr[,1],
     main = "range of the imputation error of 50 imputations e [0, 1]",
     ylim = c(0.143, 0.151), xlab="", ylab = "imputation error")
abline(h = mean(imperr[,1]), col = "darkgreen")
abline(h = median(imperr[,1]), col = "lightgreen")
```
The imputation error range is extremely small. The possible range is between 0 and 1, however here the range is between 0.143 and 0.151.

Get together imputed dataset from 50 imputations.
```{r}
# backup <- impvals
X <- do.call(rbind, impvals)
X <- data.table::as.data.table(X)
X[, (numcols) := lapply(.SD, as.numeric), .SDcols=numcols]
# backup2 <- data.table::copy(X)

# two ways of aggregating the 50 imputed values together
# Y <- aggregate(X[, ..numcols], list(Plotn=X$Plotn), mean)
Y <- X[, lapply(.SD, mean, na.rm=T), .SDcols=numcols, by=Plotn]
Y <- data.table::data.table(Y)
```

Compare imputed values with real values. Creates the pdf `imputed_values.pdf`
```{r, eval=F}
pdf("imputed_values.pdf", paper="a4r")
par(mfrow = c(2,7))
for(i in 1:length(numcols)){
  x <- rep(1, 150)
  colname <- numcols[i]
  # length of the imputed value vector
  rowlocations <- naloc[, colname]
  y <- Y[rowlocations, get(colname)]
  plot(x, befunbackup[, get(colname)], xlab="", ylab="range of values", main=colname, sub=paste(length(y), "NAs"))
  x <- x[0:length(y)]
  points(x, y, col="red",pch=19)
}
dev.off()
```

Take out soil variables again and store imputed grassland function dataset.
```{r}
# take out colnames of glsoil_unscaled, except "Plotn"
Y[, (colnames(glsoil_unscaled)[!colnames(glsoil_unscaled) %in% c("Plotn", "Soil.type")]) := NULL]
saveRDS(Y, file="imputed_function_values.rds")
# clean a bit
imputed_grlfuns <- data.table::copy(Y)
```

# Calculate mini-multifunctionalities
The mini-multifunctionalities are calculated from the imputed values.

## soilCflxs
Enzymes related to soil C. All measured in the year 2011.
```{r}
sce <- imputed_grlfuns[, c("beta_Glucosidase", "N_Acetyl_beta_Glucosaminidase", "Xylosidase")]
# take z-scores of the functions
imputed_grlfuns[, "soilCflxs" := multidiv(sce, sc="sd", cent=TRUE)[,1]]
rm(sce)
```

## soilNflxs
Enzymes related to soil N. A measure of soil N cycling with enzyme activities and functional gene abundances

amoA_AOB and A are from both 2011 and 2016, took the mean of both years.
```{r}
nce <- imputed_grlfuns[,c("Urease", "DEA","Potential.nitrification2011", "Potential.nitrification2014","nifH","amoA_AOB.2011","amoA_AOA.2011", "amoA_AOB.2016", "amoA_AOA.2016", "nxrA_NS", "16S_NB")]
# take mean of multi-year-measurements
nce[, "amoA_AOB" := apply(nce[,c("amoA_AOB.2011", "amoA_AOB.2016")],1, mean)]
nce[, "amoA_AOA" := apply(nce[,c("amoA_AOA.2011", "amoA_AOA.2016")],1, mean)]
nce[, "Potential.nitrification" := apply(nce[, c("Potential.nitrification2014", "Potential.nitrification2011")], 1, mean)]
nce[, c("amoA_AOB.2011", "amoA_AOB.2016", "amoA_AOA.2011", "amoA_AOA.2016", "Potential.nitrification2014", "Potential.nitrification2011") := NULL]

imputed_grlfuns[, "soilNflxs" := multidiv(nce, sc="sd", cent=TRUE)[,1]]
rm(nce)
```

## P_loss_comb
combination of PRI and P_loss.

mean of P_loss 2011 and 2015.
```{r}
plc <- imputed_grlfuns[, c("P_loss2011", "P_loss2015", "PRI")]
# take mean of P_loss 2011 and 2015
plc[, "P_loss" := apply(plc[,c("P_loss2011", "P_loss2015")],1, mean)]
plc[, c("P_loss2011", "P_loss2015") := NULL]
imputed_grlfuns[, "P_loss_comb" := multidiv(plc, sc="sd", cent=TRUE)[,1]]; rm(plc)
```



```{r}
# select variables which are included in betadiv multifun analysis
usedforBetadivMultifun <- usedforBetadivMultifun[!usedforBetadivMultifun == "Plot"]
imputed_grlfuns <- imputed_grlfuns[, ..usedforBetadivMultifun]
```


# Correlations
Of the non-factor columns only
```{r}
# the dataset is complete now, use "complete.obs" for the cor() function now
M <- cor(imputed_grlfuns[, !colnames(imputed_grlfuns) %in% "Plotn", with=F], use="complete.obs")

# imputed_grlfun_corrplot1
corrplot::corrplot(M,type="lower",addCoef.col = "black",method="color",diag=F, tl.srt=1, tl.col="black", mar=c(0,0,0,0), number.cex=0.6)

# imputed_grlfun_corrplot2
corrplot::corrplot(M, type = "upper", tl.col="black", tl.srt=40, diag = F)

# only show high correlations
tres <- 0.7
M[which(M < tres & M > -tres)] <- 0
corrplot::corrplot(M, type = "upper", tl.col="black", tl.srt=40, diag = F)
```
- PRI and NRI: constructed partly with same data
- PRI and P_loss_comb : the latter contains the first

- Groundwater recharche and soil depth: ? the deeper the soil, the less groundwater recharche? soil depth defines the soil type. 

- SoilOrganicC and Soil.C.stock : 

old stuff
```{r}


####################
# 5. IMPUTATION
# Impute
imputeall<-missForest(befun[,-1])
imp_error <- imputeall$OOBerror

#extract imputed data and retransform everything
impdat <- data.table(Plot0=befun$Plot, exp(imputeall$ximp[,-35])-1, Exploratory=imputeall$ximp[,35])
impdat$pathogen.infection <- impdat$pathogen.infection-abs(minpath)
impdat$forage.quality <- impdat$forage.quality-abs(minfor)

# exclude all columns that are not functions : see script "calculate_multifunctionality_dissimilarity_DEMO.r

#################
# 6. CLEANING
#################
# deleting all stored variables which I will not use any more in the analysis.
rm(befun) ; rm(M) ; rm(imputeall)  ; rm(funs) ; rm(minpath) ; rm(minfor)



# ##########################################
# # 7. DIFFERENT WAY OF ERROR ESTIMATION
# # Check if missForest is doing a good job
# # read functions table
# # befun is the table I use.
# 
# # calculate  % of missing data in each function (i.e. column)
# NA_per_column <- apply(befun,2,function(c) sum(is.na(c))/length(c))
# # remove NA's from the table (rows) - so you have a dataset with no NAs
# 
# navals <- apply(befun, 1, function(r) any(is.na(r)))
# noNA_befun <- befun[!navals,] ; rm(navals)
# original_noNA_befun <- noNA_befun
# 
# # randomly remove the same % in each column (as we had in the real dataset)
# settoNA <- round(NA_per_column*nrow(noNA_befun)) ; rm(NA_per_column) # the amount of values to set to NA
# whichrowsNA <- list()
# for(i in 1:length(settoNA)){
#   rows <- sample(1:nrow(noNA_befun), settoNA[[i]], replace=F) # get random rows to set to NA
#   noNA_befun[rows,i] <- NA
#   # save which rows were set to NA where
#   whichrowsNA[[i]] <- rows
# }
# rm(i) ; rm(rows) ; rm(settoNA)
# 
# # impute with missForest
# imputeall<-missForest(noNA_befun[,-1])
# imputeall$OOBerror # 12% of estimated error
# 
# check_imp <- as.data.frame(imputeall$ximp)
# 
# # compare imputed with real data (calculate NRMSE=normalized root mean square error value)
# nrmse(imputeall$ximp, noNA_befun[,-1], original_noNA_befun[,-1])
#
# rm(noNA_befun)
# ##########
# # visualization
# original_noNA_befun <- as.data.frame(original_noNA_befun)
# imp_no <- c(check_imp[whichrowsNA[[22]],22],check_imp[whichrowsNA[[18]],18], check_imp[whichrowsNA[[17]],17],
#             check_imp[whichrowsNA[[16]],16] , check_imp[whichrowsNA[[19]],19])
# rm(check_imp)
# true_no <- c(original_noNA_befun[whichrowsNA[[22]],22],original_noNA_befun[whichrowsNA[[18]],18],original_noNA_befun[whichrowsNA[[17]],17],
#              original_noNA_befun[whichrowsNA[[16]],16], original_noNA_befun[whichrowsNA[[19]],19])
# rm(original_noNA_befun) ; rm(whichrowsNA)
# imp_true_no <- cbind(imp_no,true_no, c(rep(22,11),rep(18,8),rep(17,8),rep(16,6), rep(19,7))) ; rm(imp_no) ; rm(true_no)
# plot(imp_true_no[,1],imp_true_no[,2] ,main="imputed versus true", col=imp_true_no[,3],pch=19,
#      xlab="imputed", ylab="true")
# rm(imp_true_no)
# abline(a=0, b=1,col="grey")
# # without standardization, there is a clustering (because of the different range the values are in)
# # with standardization, the clusters disappear.

```


