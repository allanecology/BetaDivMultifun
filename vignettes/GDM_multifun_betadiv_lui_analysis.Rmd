---
output:
  pdf_document: default
  html_document: default
---
<!--
%\VignetteEngine{knitr}
%\VignetteIndexEntry{ISMB Twitter Analysis}
-->
*how to work on this file*

There are TODO's, WAITING's


*note:*

This is where the analysis is performed and described.
All necessary functions will be written in R files within the folder R/.
As described [here](http://rmflight.github.io/post/vignette-analysis/).


# Reproducibility
This vignette and package were built as recommended by the blogpost of [Hilary Parker](https://hilaryparker.com/2014/04/29/writing-an-r-package-from-scratch/), [the book "R packages"](http://r-pkgs.had.co.nz/) and the idea of using `R packages` for an analysis is coming from Robert M. Flight's blogposts, where he explains [why](http://rmflight.github.io/post/analyses-as-packages/) and [how](http://rmflight.github.io/post/vignette-analysis/) to use `R package` for an analysis.

Working with [Google's R Style Guide](https://google.github.io/styleguide/Rguide.xml).

## packrat
In order to be clear on R package versions and dependencies, [packrat](http://rstudio.github.io/packrat/) was used. **TODO : get infos abou how to use packrat**
```{r, eval=F}
# devtools::install_github("rstudio/packrat")
require(packrat)
```
Follow the [walktrough](http://rstudio.github.io/packrat/walkthrough.html) from packrat, which they highly recommend.


## personalisation
To run this script with personal, non-public content, store global variables (as e.g. path to the datasets) with the following function, if they are not in the current directory.
```{r, eval=F}
setNonpublicVariables(".", ".", ".")
```


# Dataset
## about
<!-- [TODO] : table will be updated -->
<!-- | var name   | ID     | content                   | year | -->
<!-- | ---------- | ------ | ------------------------- | ---- | -->
<!-- |   soil     | bla    | bla                       |      | -->
<!-- |   pH       | bli    | blu                       |  | -->
<!-- | spdivGRL   | ... | species diversity in grasslands |  | -->
<!-- | spinfoGRL  | ... | info about species diversity in grasslands |  | -->
<!-- | landscape  | ... | ... |  | -->
<!-- | plotNames  | ... | ... |  | -->
<!-- | plotCoord  | | |  | -->
<!-- | covar      | | environmental coovariates |  | -->
<!-- | funct       | EP grass functions & services.txt | Ecosystem functions data, pre-cleaned by eric |  | -->
<!-- | lui        | 20907 | land-use intensity data |  | -->
<!-- | lui5y      | ? by-hand | some update of lui dataset | 2006-2010 | -->
<!-- ```{r, eval=F} -->
<!-- varnames <- c("soil", "pH", "spdivGRL", "spinfoGRL", "landscape", "plotNames", "plotCoord", "covar", "funs", "lui") -->
<!-- varIDs <- c(NA, NA, NA, NA, NA, NA, NA, NA, NA, 20907) -->
<!-- ``` -->


## obtain dataset from BExIS
With account on [BExIS](https://www.bexis.uni-jena.de). Using the script `accesBexis.R` from Bexis. Download and store it a folder with path `accesBexispath`.
```{r, eval=F}
# accesBexispath <- "C:/Users/nschenk/Documents/BEF/BExIS/"
source(paste(accesBexispath,"accessBexis.R", sep=""))
```

As this script is public, user-input is requested to fill in variables `datasetid`, `user`, `pswd` and a name for the downloaded dataset. The first 3 variables are requested by the function `read.service` from the script `accessBexis.R`.

**single dataset download**
```{r, eval=F}
my_name <- readline(prompt="BExIS user name : ")
my_password <- readline(prompt="BExIS password : ")
my_datasetid <- readline(prompt="BExIS dataset ID : ")
my_varname <- readline(prompt="BExIS dataset name which will be used in R")
downloaded_dataset <- read.service(datasetid = my_datasetid, user = my_name, pswd = my_password)
assign(my_varname, downloaded_dataset)
# delete unwanted variables
rm(my_name, my_password, my_datasetid); gc()
```


## land-use intensity (LUI)
LUI is standardised among five years, from 2006-2010. The data used for LUI is assembled data, therefore get it from the assembled_data folder.


### the combined index
The combined index of G+M+F has been shown to better predict patterns than the individual components (Bluthgen, 2012). 

$$LUI_i = \sqrt{\frac{g_i}{\bar{g}} + \frac{m_i}{\bar{m}} + \frac{f_i}{\bar{f}}}  \textsf{ , where } \bar{c} = \bar{c}_{2006} + ... + \bar{c}_{2010} \textsf{  for } c \in \{g, m, f\} \textsf{ and } i \textsf{ corresponds to plots } \in \{1, ... , 150\}$$

- **normalisation** by division with mean (alternative : $ x_{new} = \frac{x_i - x_{min}}{x_{max} - x_{min}}$) . Division with mean was chosen because it is not as dependent of **outliers**. The mean was much more consistent among the years and the regions. Normalisation and not standardisation because normalisation keeps outliers.

- standardisation : $z_i = \frac{x_i - \mu}{\sigma}$, would lead to centering around 0, standard deviation = 1. makes distribution normal, better for optimisation, PCA, ... not in this case, because it takes out outliers and can change some identities of the data.

- **square root transformation** to achieve a more even distribution and reduce the effect of outliers in regression (Bluthgen, 2012)


### averaging over years

In many cases, a long-term measure of land-use intensity may be desirable which integrates inter-annual variability. (Bluthgen, 2012)

Two ways of averaging are possible, first average each component $\in \{g, m, f\}$ over the 5 years and then sum the averages to $LUI$, or first calculating $LUI$ for each year and averaging the 5 measurements. It happens to not matter, because
$$\bar{LUI} = \bar{g} + \bar{m} + \bar{f} \textsf{  whenever they contain the same number of elements (equal weighting)}$$
This was true if we would not **transform** LUI. But as we do, it is possible to either transform LUI for each years separately and average the transformed values or average each component separatley first, combine them to LUI and transform after.

therefore, 
$$LUI_i = \sqrt{\sum_{c \in \{g, m, f\}} \frac{\frac{c_{i,2006}}{\bar{c}} + ... + \frac{c_{i,2010}}{\bar{c}}}{ N_{years}}}  \textsf{  or alternatively }  LUI_i \frac{\sum_{y \in \{2006, ... , 2010\}} \sqrt{ \frac{g_{i,y}}{\bar{g}} + \frac{m_{i,y}}{\bar{m}} + \frac{f_{i,y}}{\bar{f}}}}{N_{years}}  $$
or shortly:
$$ LUI_i = \sqrt{g_{2006, ... , 2010} + m_{2006, ... , 2010} + f_{2006, ... , 2010}} \textsf{  or alternatively } LUI_i = \frac{LUI_{2006} + ... + LUI_{2010}}{N_{years}}= $$

- **But** when should we apply the transformation? in the very end, right?

TODO : I would opt for transformation first - average later. Because I have 3 measurements in 3 different years, which are independent of each other. Transforming each of them individually would make them more comparable (right?)




```{r, eval=F}
LUI <- loadAndCleanLUI(path=pathtoASSEMBLEDdata)
```

Average of LUI across time, combining the years 2006, 2007, 2008, 2009 and 2010 (5 years). For each year, data of all plots is available. 

```{r, eval=F}
# calculate the mean of each G,M,F across all years separately
Gmean <- mean(lui5y$TotalGrazing)
Mmean <- mean(lui5y$TotalMowing)
Fmean <- mean(lui5y$TotalFertilization)


```




### variation in LUI
TODO calculate variation in LUI of many years. Standardize each m,g amd f with the average value across ALL years, to keep the variation!--> do this by hand, not with the online LUI tool!


## Ecosystem functions

```{r, eval=F}
funct <- loadAndCleanEcosystemFunctions(path=pathtodata)
```
WAITING : checking correlations between functions - follow eric's script "create function database.R" once it is clear how to deal with the functions.
```{r}
# WAITING : here! check in other file how I found out which input variables are too correlated to include. 
```



## Biodiversity
We will average biodiversity data across several years. Not for OTU measures, as they differ too much across years. For presence-absence, we say that a species is present if it was present at least in one year. 

TODO : is the diversity correlated among years? (can we combine years?)

```{r}

```



### Biodiversity abundance
**leave abundance out for the moment** to make things easier. WAITING for need to work with abundance data.

For abundance : take one year and standardise all species per plot. All species of 1 plot should sum to 1. Then, average across years of these standardised values. Do this for bats and birds separately before combining them, because bats and bird abundances were measured differently. (Bat abundance was the amount of sounds measured, but one bat may produce several sounds. Birds were measured visually and as well with sounds, but different than bats.)

Open question: is it possible to work with relative abundances for Betadiversity? Does that impact the abundance turnover component?

We may lose situations where one plot has many species and another plot has a low amount of species. So the question is - is the value changing a lot? Standardisation can only happen either per year OR per plot. Per plot makes sense, because presumably the same person measured the diversity of a given plot, and the abundance can differ among persons. To keep the situation mentioned above, we would need to standardise per year and not per plot. According to Eric, that would only be the case in a low number of situations. But would be needed to confirm it.
